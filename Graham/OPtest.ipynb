{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import yaml\n",
    "from random import randint\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "from parcels import FieldSet, Field, VectorField, ParticleSet, JITParticle, ParcelsRandom, Variable\n",
    "\n",
    "sys.path.append('/scratch/jvalenti/OParcels_runs/Source') \n",
    "from OP_functions import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only for multicore runs\n",
    "def simple_partition_function(coords, mpi_size=1):\n",
    "    \"\"\"A very simple partition function\n",
    "    that assigns particles to processors\n",
    "    \"\"\"\n",
    "    return np.linspace(0, mpi_size, coords.shape[0], endpoint=False, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ['/home/jvalenti/scratch/OParcels_runs/Parcels_outfall/outfall_runs.yaml']\n",
    "restart = 0\n",
    "paths = path()\n",
    "# Suppress FutureWarning messages\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will run for 1 days, starting at 2019-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "param = load_config(config)\n",
    "#Definitions\n",
    "start = datetime(param['startdate']['year'], param['startdate']['month'], param['startdate']['day']) #Start date\n",
    "length = param['param']['length'] # Set Time length [days] \n",
    "dt = param['param']['dt'] #toggle between - or + to pick backwards or forwards \n",
    "N = param['param']['N'] # Name of deploy loc file\n",
    "dd = param['param']['dd'] #max depth difference z in N\n",
    "name = param['file']['name'] #name output file\n",
    "dtp = param['param']['dtp'] #how often particle released in hours\n",
    "odt = param['param']['odt'] #how often data is recorded\n",
    "rrr = param['param']['r'] #radious of particle deployment\n",
    "MFc = param['param']['MFc']\n",
    "\n",
    "duration = timedelta(days=length)\n",
    "print(f\"The model will run for {duration.days} days, starting at {start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will release 345 particle every timestep\n"
     ]
    }
   ],
   "source": [
    "lon, lat, z = pandas_deploy(N,MFc,rrr,dd,dtp)\n",
    "N = len(lat)\n",
    "print(f\"The model will release {N} particle every timestep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "daterange = [start+timedelta(days=i) for i in range(length)]\n",
    "if restart == 0:\n",
    "    fn =  name +'_'.join(d.strftime('%Y%m%d')+'_1n' for d in [start, start+duration]) + '.zarr'\n",
    "else:\n",
    "    fn =  name + '.zarr'\n",
    "outfile = os.path.join('/scratch/jvalenti/OParcels_runs/Parcels_outfall/results/', fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: File /home/jvalenti/scratch/OParcels_runs/grid/coordinates_seagrid_SalishSea201702.nc could not be decoded properly by xarray (version 2023.12.0). It will be opened with no decoding. Filling values might be wrongly parsed.\n"
     ]
    }
   ],
   "source": [
    "####BUILD FIELDS FOR SIMULATION######\n",
    "#Fill in the list of variables that you want to use as fields\n",
    "varlist=['U','V','W']\n",
    "filenames,variables=filename_set(start,length,varlist)\n",
    "dimensions = {'lon': 'glamf', 'lat': 'gphif', 'depth': 'depthw','time': 'time_counter'}\n",
    "field_set=FieldSet.from_nemo(filenames, variables, dimensions, allow_time_extrapolation=True, chunksize='auto')\n",
    "\n",
    "#Find file names and variable names ###'Diat','Flag'###\n",
    "varlist=['US','VS','WL','R','T','S','ssh','Bathy','Kz','totdepth','Vol']\n",
    "filenames,variables=filename_set(start,length,varlist)\n",
    "\n",
    "#Add Stokes Drift fields\n",
    "dimensions = {'lon': 'longitude', 'lat': 'latitude', 'time': 'time'}\n",
    "us = Field.from_netcdf(filenames['US'], variables['US'], dimensions,allow_time_extrapolation=True, chunksize='auto')\n",
    "vs = Field.from_netcdf(filenames['VS'], variables['VS'], dimensions,allow_time_extrapolation=True, chunksize='auto')\n",
    "wl = Field.from_netcdf(filenames['WL'], variables['WL'], dimensions,allow_time_extrapolation=True, chunksize='auto')\n",
    "field_set.add_field(us)\n",
    "field_set.add_field(vs)\n",
    "field_set.add_field(wl)\n",
    "field_set.add_vector_field(VectorField(\"stokes\", us, vs, wl))\n",
    "\n",
    "#Add Vertical diffusivity coefficient field\n",
    "dimensions = {'lon': 'glamt', 'lat': 'gphit', 'depth': 'depthw','time': 'time_counter'}\n",
    "Kz = Field.from_netcdf(filenames['Kz'], variables['Kz'], dimensions,allow_time_extrapolation=True, chunksize='auto')\n",
    "field_set.add_field(Kz)\n",
    "\n",
    "#Add fields located at node T\n",
    "dimensions = {'lon': 'glamt', 'lat': 'gphit', 'depth': 'deptht','time': 'time_counter'}\n",
    "#Diat = Field.from_netcdf(filenames['Diat'], variables['Diat'], dimensions,allow_time_extrapolation=True)\n",
    "#Flag = Field.from_netcdf(filenames['Flag'], variables['Flag'], dimensions,allow_time_extrapolation=True)\n",
    "R = Field.from_netcdf(filenames['R'], variables['R'], dimensions,allow_time_extrapolation=True, chunksize='auto')\n",
    "S = Field.from_netcdf(filenames['S'], variables['S'], dimensions,allow_time_extrapolation=True, chunksize='auto')\n",
    "T = Field.from_netcdf(filenames['T'], variables['T'], dimensions,allow_time_extrapolation=True, chunksize='auto')\n",
    "#field_set.add_field(Diat)\n",
    "#field_set.add_field(Flag)\n",
    "field_set.add_field(R)\n",
    "field_set.add_field(S)\n",
    "field_set.add_field(T)\n",
    "\n",
    "#Add Bathymetry 2D field\n",
    "dimensions = {'lon': 'glamt', 'lat': 'gphit'}\n",
    "Bth = Field.from_netcdf(filenames['Bathy'], variables['Bathy'], dimensions,allow_time_extrapolation=True, chunksize='auto')\n",
    "TD = Field.from_netcdf(filenames['totdepth'], variables['totdepth'], dimensions,allow_time_extrapolation=True, chunksize='auto')\n",
    "field_set.add_field(Bth)\n",
    "field_set.add_field(TD)\n",
    "\n",
    "#Add Volume 3D field\n",
    "dimensions = {'lon': 'glamt', 'lat': 'gphit', 'depth': 'depthw'}\n",
    "Vol = Field.from_netcdf(filenames['Vol'], variables['Vol'], dimensions,allow_time_extrapolation=True, chunksize='auto')\n",
    "field_set.add_field(Vol)\n",
    "\n",
    "#Add SSH \n",
    "dimensions = {'lon': 'glamt', 'lat': 'gphit','time': 'time_counter'}\n",
    "SSH = Field.from_netcdf(filenames['ssh'], variables['ssh'], dimensions,allow_time_extrapolation=True, chunksize='auto')\n",
    "field_set.add_field(SSH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPParticle(JITParticle):    \n",
    "    diameter = Variable('diameter', initial = param['particle']['diameter'])\n",
    "    length = Variable('length', initial = param['particle']['length'])\n",
    "    Ub = Variable('Ub', initial = param['particle']['Ub'])  #days to have 67% probability of unbeaching\n",
    "    tau = Variable('tau', initial =  param['particle']['tau']) # track number of particles\n",
    "    status = Variable('status', initial = 0)\n",
    "    fratio = Variable('fratio', initial = param['particle']['fratio'])\n",
    "    vvl_factor = Variable('fact', initial =  1)    \n",
    "    ws = Variable('ws', initial =  0) \n",
    "    wa = Variable('wa', initial =  0) \n",
    "    wm = Variable('wm', initial =  0) \n",
    "    cellvol = Variable('cellvol', initial =  0) # MF per parcel\n",
    "    dlat = Variable('dlat', initial =  0) \n",
    "    dlon = Variable('dlon', initial =  0) \n",
    "    ddepth = Variable('ddepth', initial =  0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if restart=='1':\n",
    "    #name_temp=find_temp(paths['out'])\n",
    "    #os.system(f\"cd {paths['out']} && parcels_convert_npydir_to_netcdf {name_temp}\")\n",
    "    #outfile=newest(paths['out'])\n",
    "    print('restarting run with '+outfile)\n",
    "    pset = ParticleSet.from_particlefile(field_set, MPParticle,outfile,restart=True)\n",
    "    outfile = outfile[:-5]+'restart.zarr'\n",
    "else:\n",
    "    if dtp == 0:\n",
    "        pset = ParticleSet.from_list(field_set, MPParticle, lon=lon, lat=lat, depth=z,time=start+timedelta(hours=odt))\n",
    "    else:\n",
    "        pset = ParticleSet.from_list(field_set, MPParticle, lon=lon, lat=lat, depth=z, repeatdt = timedelta(hours=dtp))\n",
    "#,Buoyancy,Stokes_drift,turb_mix,Displacement,Unbeaching,DeleteParticle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Don't change the location of a particle directly in a Kernel. Use particle_dlon, particle_dlat, etc.\n",
      "INFO: Output files are stored in /scratch/jvalenti/OParcels_runs/Parcels_outfall/results/Outfalls_run20190101_1n_20190102_1n.zarr.\n",
      "  0%|          | 0/86400.0 [00:00<?, ?it/s]WARNING: ParticleFile chunks are set to (156, 1), but this may lead to a significant slowdown in Parcels when many calls to repeatdt. Consider setting a larger chunk size for your ParticleFile (e.g. chunks=(int(1e4), 1)).\n",
      "100%|██████████| 86400.0/86400.0 [05:45<00:00, 250.04it/s]\n"
     ]
    }
   ],
   "source": [
    "pset.execute([Advection],\n",
    "                runtime=duration, \n",
    "                dt=dt,\n",
    "                output_file=pset.ParticleFile(name=outfile, outputdt=timedelta(hours=odt)),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jvalenti/miniforge3/envs/Parcels_24/lib/python3.11/site-packages/xarray/backends/plugins.py:159: RuntimeWarning: 'netcdf4' fails while guessing\n",
      "  warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n",
      "/home/jvalenti/miniforge3/envs/Parcels_24/lib/python3.11/site-packages/xarray/backends/plugins.py:159: RuntimeWarning: 'scipy' fails while guessing\n",
      "  warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "ds = xr.load_dataset(outfile,decode_times=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Parcels_24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
