{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "from parcels import FieldSet, Field, VectorField, ParticleSet, JITParticle, ErrorCode, ParcelsRandom, Variable\n",
    "\n",
    "sys.path.append('/home/jvalenti/MOAD/analysis-jose/Source')\n",
    "from OP_functions import *\n",
    "from OP_Kernels_e3t import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = '/home/jvalenti/MOAD/analysis-jose/OParcels/yaml/unidiste3t.yaml'\n",
    "local = 0\n",
    "param = load_config1(config)\n",
    "#Definitions\n",
    "start = datetime(param['startdate']['year'], param['startdate']['month'], param['startdate']['day']) #Start date\n",
    "length = param['param']['length'] # Set Time length [days] \n",
    "dt = param['param']['dt'] #toggle between - or + to pick backwards or forwards \n",
    "N = param['param']['N'] # number of deploying locations\n",
    "n = param['param']['n'] # 1000   # number of particles per location\n",
    "dmin = param['param']['dmin'] #minimum depth\n",
    "dd = param['param']['dd'] #max depth difference from dmin\n",
    "name = param['file']['name'] #name output file\n",
    "dtp = param['param']['dtp'] #how often particle released in hours\n",
    "odt = param['param']['odt'] #how often data is recorded\n",
    "rrr = param['param']['r'] #radious of particle deployment\n",
    "distr = param['param']['distr']\n",
    "MFc = param['param']['MFc']\n",
    "# Define paths\n",
    "paths = path(local)\n",
    "#Set outfall coordinates (Modify to choose other deploying location)    \n",
    "#coord=xr.open_dataset(paths['coords'],decode_times=False)\n",
    "clat = param['param']['lats']\n",
    "clon = param['param']['lons']\n",
    "#clon, clat = [float(outf_lon)],[float(outf_lat)] \n",
    "duration = timedelta(days=length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamps(start,length):\n",
    "    timestamps=[]\n",
    "    duration = timedelta(days=length)\n",
    "    for day in range(duration.days):\n",
    "        timestamps.append([start + timedelta(days=day)])\n",
    "    return np.array(timestamps, dtype='datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set deploy locations\n",
    "if distr == 'hmg':\n",
    "    clat,clon = p_unidist(N,N)\n",
    "    N = len(clat)\n",
    "elif distr == 'trst':\n",
    "    clat,clon = transect_deploy(clat,clon,N)\n",
    "elif distr == 'std':\n",
    "    N = len(param['param']['lats'])\n",
    "elif distr == 'pd':\n",
    "    clat, clon, N = pandas_deploy(N,MFc,int(dtp))\n",
    "    n = 1\n",
    "    print(N)\n",
    "\n",
    "x_offset, y_offset, z = p_deploy(N,n,dmin,dd,rrr)\n",
    "\n",
    "lon = np.zeros([N,n])\n",
    "lat = np.zeros([N,n])\n",
    "for i in range(N):\n",
    "    lon[i,:]=(clon[i] + x_offset[i,:])\n",
    "    lat[i,:]=(clat[i] + y_offset[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: File /ocean/jvalenti/MOAD/grid/coordinates_seagrid_SalishSea201702.nc could not be decoded properly by xarray (version 2023.5.0).\n",
      "         It will be opened with no decoding. Filling values might be wrongly parsed.\n"
     ]
    }
   ],
   "source": [
    "#Set start date time and the name of the output file\n",
    "\n",
    "daterange = [start+timedelta(days=i) for i in range(length)]\n",
    "fn =  name + '_'.join(d.strftime('%Y%m%d')+'_1n' for d in [start, start+duration]) + '.zarr'\n",
    "outfile = os.path.join(paths['out'], fn)\n",
    "####BUILD FIELDS FOR SIMULATION######\n",
    "#Fill in the list of variables that you want to use as fields\n",
    "varlist=['U','V','W']\n",
    "filenames,variables=filename_set(start,length,varlist,local)\n",
    "dimensions = {'lon': 'glamf', 'lat': 'gphif', 'depth': 'depthw','time': 'time_counter'}\n",
    "field_set=FieldSet.from_nemo(filenames, variables, dimensions, allow_time_extrapolation=True)\n",
    "\n",
    "#Find file names and variable names\n",
    "varlist=['US','VS','WL','Diat','Flag','R','T','S','FS','ssh','Bathy','Kz','totdepth','Vol']\n",
    "filenames,variables=filename_set(start,length,varlist,local)\n",
    "\n",
    "#Add Stokes Drift fields\n",
    "dimensions = {'lon': 'longitude', 'lat': 'latitude', 'time': 'time'}\n",
    "us = Field.from_netcdf(filenames['US'], variables['US'], dimensions,allow_time_extrapolation=True)\n",
    "vs = Field.from_netcdf(filenames['VS'], variables['VS'], dimensions,allow_time_extrapolation=True)\n",
    "wl = Field.from_netcdf(filenames['WL'], variables['WL'], dimensions,allow_time_extrapolation=True)\n",
    "field_set.add_field(us)\n",
    "field_set.add_field(vs)\n",
    "field_set.add_field(wl)\n",
    "field_set.add_vector_field(VectorField(\"stokes\", us, vs, wl))\n",
    "\n",
    "#Add Vertical diffusivity coefficient field\n",
    "dimensions = {'lon': 'glamt', 'lat': 'gphit', 'depth': 'depthw','time': 'time_counter'}\n",
    "Kz = Field.from_netcdf(filenames['Kz'], variables['Kz'], dimensions,allow_time_extrapolation=True)\n",
    "field_set.add_field(Kz)\n",
    "\n",
    "#Add fields located at node T\n",
    "dimensions = {'lon': 'glamt', 'lat': 'gphit', 'depth': 'deptht','time': 'time_counter'}\n",
    "Diat = Field.from_netcdf(filenames['Diat'], variables['Diat'], dimensions,allow_time_extrapolation=True)\n",
    "Flag = Field.from_netcdf(filenames['Flag'], variables['Flag'], dimensions,allow_time_extrapolation=True)\n",
    "R = Field.from_netcdf(filenames['R'], variables['R'], dimensions,allow_time_extrapolation=True)\n",
    "S = Field.from_netcdf(filenames['S'], variables['S'], dimensions,allow_time_extrapolation=True)\n",
    "T = Field.from_netcdf(filenames['T'], variables['T'], dimensions,allow_time_extrapolation=True)\n",
    "field_set.add_field(Diat)\n",
    "field_set.add_field(Flag)\n",
    "field_set.add_field(R)\n",
    "field_set.add_field(S)\n",
    "field_set.add_field(T)\n",
    "\n",
    "#Add Bathymetry 2D field\n",
    "dimensions = {'lon': 'glamt', 'lat': 'gphit'}\n",
    "Bth = Field.from_netcdf(filenames['Bathy'], variables['Bathy'], dimensions,allow_time_extrapolation=True)\n",
    "TD = Field.from_netcdf(filenames['totdepth'], variables['totdepth'], dimensions,allow_time_extrapolation=True)\n",
    "field_set.add_field(Bth)\n",
    "field_set.add_field(TD)\n",
    "\n",
    "#Add Volume 3D field\n",
    "dimensions = {'lon': 'glamt', 'lat': 'gphit', 'depth': 'depthw'}\n",
    "Vol = Field.from_netcdf(filenames['Vol'], variables['Vol'], dimensions,allow_time_extrapolation=True)\n",
    "field_set.add_field(Vol)\n",
    "\n",
    "\n",
    "#Add SSH and Rivers 2D fields\n",
    "dimensions = {'lon': 'glamt', 'lat': 'gphit','time': 'time_counter'}\n",
    "SSH = Field.from_netcdf(filenames['ssh'], variables['ssh'], dimensions,allow_time_extrapolation=True)\n",
    "field_set.add_field(SSH)\n",
    "Fraser = Field.from_netcdf(filenames['FS'], variables['FS'], dimensions,allow_time_extrapolation=True,timestamps=get_timestamps(start,length))\n",
    "field_set.add_field(Fraser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPParticle = particle_maker(param)\n",
    "pset = ParticleSet.from_list(field_set, MPParticle, lon=lon, lat=lat, depth=z,time=start+timedelta(hours=odt))\n",
    "pset2 = ParticleSet.from_list(field_set, MPParticle, lon=lon, lat=lat, depth=z,time=start+timedelta(hours=odt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNELS =  Advection + pset.Kernel(Stokes_drift)+ pset.Kernel(turb_mix)+ pset.Kernel(Displacement)+ pset.Kernel(Unbeaching)\n",
    "KERNELS_2 =  Advection_2 + pset2.Kernel(Stokes_drift)+ pset.Kernel(turb_mix_2)+ pset.Kernel(Displacement_2)+ pset.Kernel(Unbeaching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Compiled ArrayMPParticleAdvection_2Stokes_driftturb_mix_2Displacement_2Unbeaching ==> /tmp/parcels-2894/lib98d87acc2ff12265ccfc780ddb505fca_0.so\n",
      "INFO: Output files are stored in /home/jvalenti/MOAD/results/Unidiste3t20190101_1n_20190102_1n.zarr.\n",
      "100%|██████████| 86400.0/86400.0 [01:26<00:00, 993.72it/s]           \n"
     ]
    }
   ],
   "source": [
    "pset2.execute(KERNELS_2,\n",
    "            runtime=duration, \n",
    "            dt=dt,\n",
    "            output_file=pset.ParticleFile(name=outfile, outputdt=timedelta(hours=odt)),\n",
    "            recovery={ErrorCode.ErrorOutOfBounds: DeleteParticle})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Compiled ArrayMPParticleAdvectionStokes_driftturb_mixDisplacementUnbeaching ==> /tmp/parcels-2894/lib4854ce06ce8b13043f09c399a7540759_0.so\n",
      "INFO: Output files are stored in /home/jvalenti/MOAD/results/Unidiste3t20190101_1n_20190102_1n.zarr.\n",
      "100%|██████████| 86400.0/86400.0 [01:22<00:00, 1051.05it/s]          \n"
     ]
    }
   ],
   "source": [
    "pset.execute(KERNELS,\n",
    "            runtime=duration, \n",
    "            dt=dt,\n",
    "            output_file=pset.ParticleFile(name=outfile, outputdt=timedelta(hours=odt)),\n",
    "            recovery={ErrorCode.ErrorOutOfBounds: DeleteParticle})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c18d5b48c0702a9e14ce9f1a358d9af7e982f07ccbb6648362fbf5930d0b5c56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
