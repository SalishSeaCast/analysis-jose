{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3249b069-318c-46cf-a0ab-422a39d81733",
   "metadata": {},
   "source": [
    "# **Template OP on salish**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b3cacf0-e987-4dcc-85ad-fa33f293ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "from parcels import FieldSet, Field, VectorField, ParticleSet, JITParticle, ErrorCode, AdvectionRK4_3D\n",
    "\n",
    "sys.path.append('/home/jvalenti/MOAD/analysis-jose/notebooks/parcels')\n",
    "from moacean_parcels.kernels import DeleteParticle, Stokes_drift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eccd4e5",
   "metadata": {},
   "source": [
    "##### Dictionary with the paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "941b8dd3-eebb-4149-af84-781e66652a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Careful with changes in the keys, these are used throughout the notebook. \n",
    "paths = {'NEMO': '/results2/SalishSea/nowcast-green.201905/',\n",
    "        'coords': '/ocean/jvalenti/MOAD/grid/coordinates_seagrid_SalishSea201702.nc',\n",
    "        'coordsWW3': '/ocean/jvalenti/MOAD/grid/WW3_grid.nc',\n",
    "        'mask': '/ocean/jvalenti/MOAD/grid/mesh_mask201702.nc',\n",
    "        'out': '/home/jvalenti/MOAD/results',\n",
    "        'home': '/home/jvalenti/MOAD/analysis-jose/notebooks/parcels',\n",
    "        'anim': '/home/jvalenti/MOAD/animations'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf052eed",
   "metadata": {},
   "source": [
    "##### Some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1a0aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_prefix(date, path, res='h'):\n",
    "    \"\"\"Construct path prefix for local SalishSeaCast results given date object and paths dict\n",
    "    e.g., /results2/SalishSea/nowcast-green.201905/daymonthyear/SalishSea_1h_yyyymmdd_yyyymmdd\n",
    "    \"\"\"\n",
    "\n",
    "    datestr = '_'.join(np.repeat(date.strftime('%Y%m%d'), 2))\n",
    "    folder = date.strftime(\"%d%b%y\").lower()\n",
    "    prefix = os.path.join(path, f'{folder}/SalishSea_1{res}_{datestr}')\n",
    "    \n",
    "    return prefix\n",
    "\n",
    "def get_WW3_path(date):\n",
    "    \"\"\"Construct WW3 results path given the date\n",
    "    e.g., /opp/wwatch3/nowcast/SoG_ww3_fields_YYYYMMDD_YYYYMMDD.nc\n",
    "    :arg date: date of WW3 record\n",
    "    :type date: :py:class:`datetime.datetime`\n",
    "    :returns: WW3 path\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "\n",
    "    # Make WW3 path\n",
    "    path = '/opp/wwatch3/nowcast'\n",
    "    datestr = [date.strftime(fmt) for fmt in ('%d%b%y', '%Y%m%d_%Y%m%d')]\n",
    "    path = os.path.join(path, datestr[0].lower(), f'SoG_ww3_fields_{datestr[1]}.nc')\n",
    "    if not os.path.exists(path):\n",
    "        raise ValueError(f\"No WW3 record found for the specified date {date.strftime('%Y-%b-%d')}\")\n",
    "\n",
    "    return path\n",
    "\n",
    "\n",
    "def p_deploy(N,n,dmin,dd,r = 1000):\n",
    "    '''p_deploy returns a random deviation for the number of deploting sites and particles and the depth'''\n",
    "\n",
    "    #r is radius of particle cloud [m]\n",
    "    deg2m = 111000 * np.cos(50 * np.pi / 180)\n",
    "    var = (r / (deg2m * 3))**2\n",
    "    x_offset, y_offset = np.random.multivariate_normal([0, 0], [[var, 0], [0, var]], [n,N]).T\n",
    "    if isinstance(dmin,int):\n",
    "        zvals1 = dmin + np.random.random_sample([n,N]).T*(dd)\n",
    "    else:\n",
    "        zvals = []\n",
    "        zvals1 = []\n",
    "        for dept in dmin:\n",
    "            zvals.append(dept + np.random.random_sample([n]).T*(dd))\n",
    "        for i in range(len(zvals)):   \n",
    "            zvals1=np.concatenate((zvals1[:],zvals[i]))\n",
    "    return x_offset, y_offset, zvals1 \n",
    "\n",
    "def filename_set(start,length,varlist=['U','V','W']):\n",
    "    '''filename,variables,dimensions = filename_set(start,duration,varlist=['U','V','W'])\n",
    "    Modify function to include more default variables\n",
    "    define start as: e.g, datetime(2018, 1, 17); length= number of days'''\n",
    "    \n",
    "    duration = timedelta(days=length)\n",
    "    #Build filenames\n",
    "    Rlist,Tlist,Ulist, Vlist, Wlist = [], [], [], [], []\n",
    "    Waveslist = []\n",
    "   \n",
    "    for day in range(duration.days):\n",
    "        path_NEMO = make_prefix(start + timedelta(days=day), paths['NEMO'])\n",
    "        Ulist.append(path_NEMO + '_grid_U.nc')\n",
    "        Vlist.append(path_NEMO + '_grid_V.nc')\n",
    "        Wlist.append(path_NEMO + '_grid_W.nc')\n",
    "        Tlist.append(path_NEMO + '_grid_T.nc')\n",
    "        Rlist.append(path_NEMO + '_carp_T.nc')\n",
    "        Waveslist.append(get_WW3_path(start + timedelta(days=day)))\n",
    "        \n",
    "\n",
    "    filenames = {\n",
    "        'U': {'lon': paths['coords'], 'lat': paths['coords'], 'depth': Wlist[0], 'data': Ulist}, # NEMO u velocity  \n",
    "        'V': {'lon': paths['coords'], 'lat': paths['coords'], 'depth': Wlist[0], 'data': Vlist}, # NEMO v velocity  \n",
    "        'W': {'lon': paths['coords'], 'lat': paths['coords'], 'depth': Wlist[0], 'data': Wlist}, # NEMO w velocity  \n",
    "        'T': {'lon': paths['coords'], 'lat': paths['coords'], 'depth': Wlist[0], 'data': Tlist}, # NEMO Temperature \n",
    "        'S': {'lon': paths['coords'], 'lat': paths['coords'], 'depth': Wlist[0], 'data': Tlist}, # NEMO Salinity \n",
    "        'R': {'lon': paths['coords'], 'lat': paths['coords'], 'depth': Wlist[0], 'data': Rlist}, # NEMO Density \n",
    "        'Bathy' : {'lon': paths['coords'], 'lat': paths['coords'], 'data': paths['mask']}, # NEMO Bathymetry \n",
    "        'US' : {'lon': paths['coordsWW3'], 'lat': paths['coordsWW3'], 'data': Waveslist}, # WW3 u component Stokes drift \n",
    "        'VS' : {'lon': paths['coordsWW3'], 'lat': paths['coordsWW3'], 'data': Waveslist}, # WW3 v component Stokes drift \n",
    "        'WL' : {'lon': paths['coordsWW3'], 'lat': paths['coordsWW3'], 'data': Waveslist}, # WW3 wavelength field\n",
    "    }\n",
    "    variables = {'U': 'vozocrtx', 'V': 'vomecrty','W': 'vovecrtz','T':'votemper','S':'vosaline','R':'sigma_theta','US':'uuss','VS':'vuss','WL':'lm','Bathy':'mbathy'}\n",
    "    for fvar in varlist:\n",
    "        if fvar == 'U':\n",
    "            dimensions = {'lon': 'glamf', 'lat': 'gphif', 'depth': 'depthw','time': 'time_counter'}\n",
    "        elif fvar == 'US':\n",
    "            dimensions = {'lon': 'longitude', 'lat': 'latitude', 'time': 'time'}\n",
    "        elif fvar == 'Bathy':\n",
    "            dimensions = {'lon': 'glamf', 'lat': 'gphif','time': 'time_counter'}\n",
    "    \n",
    "    file2,var2 = {},{}\n",
    "    for var in varlist:\n",
    "        file2[var]=filenames[var]\n",
    "        var2[var]=variables[var]\n",
    "    return file2,var2,dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c756bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Vancity outfall coordinates\n",
    "Dat=xr.open_dataset(paths['coords'],decode_times=False)\n",
    "outf_lat=Dat['nav_lat'][445,304]\n",
    "outf_lon=Dat['nav_lon'][445,304]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c4bf2f-db05-4d5f-b4bb-bdaad6578599",
   "metadata": {},
   "source": [
    "##### Define particles deploying locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28a99025-a33d-4d66-9e39-aab453f279b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2018, 12, 23) #Start date\n",
    "# Set Time length [days] and timestep [seconds]\n",
    "length = 1\n",
    "duration = timedelta(days=length)\n",
    "dt = 90 #toggle between - or + to pick backwards or forwards\n",
    "N = 6 # number of deploying locations\n",
    "n = 100 # 1000   # number of particles per location\n",
    "dmin = [0,0,0,0,0,70] #minimum depth\n",
    "dd = 20 #max depth difference from dmin\n",
    "x_offset, y_offset, z = p_deploy(N,n,dmin,dd)\n",
    "\n",
    "# Choose horizontal centre of the particle cloud\n",
    "clon = [-123.901172,-125.155849,-123.207648,-122.427508,-123.399769,float(outf_lon)]\n",
    "clat = [49.186308,49.975326,49.305448,47.622403,48.399420,float(outf_lat)]  \n",
    "\n",
    "# Add the offset to obtain a random distribution for the particles at each deploy site\n",
    "lon = np.zeros([N,n])\n",
    "lat = np.zeros([N,n])\n",
    "for i in range(N):\n",
    "    lon[i,:]=(clon[i] + x_offset[i,:])\n",
    "    lat[i,:]=(clat[i] + y_offset[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92d6511f-3d0c-4a98-ad32-0d4cb970a2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jvalenti/MOAD/results/waves20181223_1n_20181224_1n.nc\n"
     ]
    }
   ],
   "source": [
    "#Set start date time and the name of the output file\n",
    "name = 'waves' #name output file\n",
    "daterange = [start+timedelta(days=i) for i in range(length)]\n",
    "fn =  name + '_'.join(d.strftime('%Y%m%d')+'_1n' for d in [start, start+duration]) + '.nc'\n",
    "outfile = os.path.join(paths['out'], fn)\n",
    "print(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e63f2-3fb8-4526-b45a-ce5644646287",
   "metadata": {},
   "source": [
    "##### Setting up NEMO and WW3 fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "922eb3dc-e34d-4102-b1d4-4df9de8b2f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in the list of variables from NEMO that you want to use as fields (If you get the a NameError, make sure that the field paths are included in filename_set() function)\n",
    "varlist=['U','V','W']\n",
    "filenames,variables,dimensions=filename_set(start,length,varlist)\n",
    "field_set=FieldSet.from_nemo(filenames, variables, dimensions, allow_time_extrapolation=True)\n",
    "\n",
    "#Fill in the list of variables from WW3 that you want to use as fields\n",
    "varlist=['US','VS','WL']\n",
    "filenames,variables,dimensions=filename_set(start,length,varlist)\n",
    "\n",
    "#Load the fields from the WW3 data\n",
    "us = Field.from_netcdf(filenames['US'], variables['US'], dimensions,allow_time_extrapolation=True)\n",
    "vs = Field.from_netcdf(filenames['VS'], variables['VS'], dimensions,allow_time_extrapolation=True)\n",
    "wl = Field.from_netcdf(filenames['WL'], variables['WL'], dimensions,allow_time_extrapolation=True)\n",
    "\n",
    "#You can either add the fields by themselves or as a Vectorfield the second option is more convenient to use inside the kernel\n",
    "#field_set.add_field(us) #field_set.add_field(vs) #field_set.add_field(wl)\n",
    "field_set.add_vector_field(VectorField(\"stokes\", us, vs, wl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53f87621-a497-4575-85ba-18ec93118e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Compiled ArrayJITParticleAdvectionRK4_3DStokes_drift ==> /tmp/parcels-2894/lib221cc6acf513979cf03ab0c0e06d6820_0.so\n",
      "INFO: Temporary output files are stored in /home/jvalenti/MOAD/results/out-BDKBBXEV.\n",
      "INFO: You can use \"parcels_convert_npydir_to_netcdf /home/jvalenti/MOAD/results/out-BDKBBXEV\" to convert these to a NetCDF file during the run.\n",
      "100% (86400.0 of 86400.0) |##############| Elapsed Time: 0:00:42 Time:  0:00:42\n"
     ]
    }
   ],
   "source": [
    "pset = ParticleSet.from_list(field_set, JITParticle, lon=lon, lat=lat, depth=z, time=start+timedelta(hours=2))\n",
    "\n",
    "kernel_Sd = pset.Kernel(Stokes_drift)\n",
    "\n",
    "pset.execute(AdvectionRK4_3D + kernel_Sd, \n",
    "             runtime=duration, \n",
    "             dt=dt,\n",
    "             output_file=pset.ParticleFile(name=outfile, outputdt=timedelta(hours=1)),\n",
    "             recovery={ErrorCode.ErrorOutOfBounds: DeleteParticle})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
