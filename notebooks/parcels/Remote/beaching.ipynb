{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3249b069-318c-46cf-a0ab-422a39d81733",
   "metadata": {},
   "source": [
    "# **Template OP on salish**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b3cacf0-e987-4dcc-85ad-fa33f293ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "from parcels import FieldSet, Field, VectorField, ParticleSet, JITParticle, ErrorCode, ParcelsRandom\n",
    "\n",
    "sys.path.append('/home/jvalenti/MOAD/analysis-jose/notebooks/parcels')\n",
    "from Kernels_beaching import DeleteParticle, Buoyancy, AdvectionRK4_3D, Stokes_drift, Beaching\n",
    "from OP_functions_beaching import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10e0ace",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "941b8dd3-eebb-4149-af84-781e66652a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "local = 0 #Set to 0 when working on server\n",
    "paths = path(local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "206d74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dat=xr.open_dataset(get_WW3_path(datetime(2018, 12, 23)))\n",
    "path_NEMO = make_prefix(datetime(2018, 12, 23), paths['NEMO'])\n",
    "Dat0=xr.open_dataset(path_NEMO + '_grid_W.nc')\n",
    "Dat=xr.open_dataset(path_NEMO + '_grid_T.nc')\n",
    "coord=xr.open_dataset(paths['coords'],decode_times=False)\n",
    "WW3 = xr.open_dataset(get_WW3_path(datetime(2018, 12, 23)))\n",
    "batt=xr.open_dataset(paths['mask'],decode_times=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879cd801",
   "metadata": {},
   "source": [
    "## Define and save mask for distance to coast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "518b09b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def maskcoast(ilat,jlon):\n",
    "#     baty = batt.mbathy[0,:,:]\n",
    "#     maski = 0\n",
    "#     if baty[ilat,jlon]>1e-1:\n",
    "#         if baty[ilat+1,jlon] == 0 or baty[ilat+1,jlon+1] == 0 or baty[ilat+1,jlon-1] == 0:\n",
    "#             maski = 1\n",
    "#         elif baty[ilat,jlon] == 0 or baty[ilat,jlon+1] == 0 or baty[ilat,jlon-1] == 0:\n",
    "#             maski = 1\n",
    "#         elif baty[ilat-1,jlon] == 0 or baty[ilat-1,jlon+1] == 0 or baty[ilat-1,jlon-1] == 0:\n",
    "#             maski = 1\n",
    "#     return maski\n",
    "# maskd = np.zeros(batt.mbathy.shape)\n",
    "# baty = batt.mbathy[0,:,:]\n",
    "# for i in range(baty.shape[0]):\n",
    "#     for j in range(baty.shape[1]):\n",
    "#         maskd[0,i,j]=maskcoast(i,j)\n",
    "# batt=xr.open_dataset(paths['mask'],decode_times=False)\n",
    "# dist=xr.DataArray(attrs={'d':maskd})\n",
    "# batt['d']=(batt.mbathy.dims,maskd)\n",
    "# batt.to_netcdf(path='/ocean/jvalenti/MOAD/grid/mesh_maskd201702.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10b6fba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clat,clon = p_unidist(coord.gphif[0,:,:],coord.glamf[0,:,:],batt.mbathy[0,:,:],10,10)\n",
    "with open('clat.txt') as f:\n",
    "    clat = f.read()\n",
    "    clat= clat[1:-1]\n",
    "    clat0 = clat.split(\",\")\n",
    "    f.close()\n",
    "with open('clon.txt') as f:\n",
    "    clon = f.read()\n",
    "    clon=clon[1:-1]\n",
    "    clon0 = clon.split(\",\")\n",
    "    f.close()\n",
    "    \n",
    "clat,clon=[],[]\n",
    "for i in range(len(clat0)):\n",
    "    clat.append(float(clat0[i]))\n",
    "    clon.append(float(clon0[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c4bf2f-db05-4d5f-b4bb-bdaad6578599",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28a99025-a33d-4d66-9e39-aab453f279b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2018, 10, 1) #Start date\n",
    "# Set Time length [days] and timestep [seconds]\n",
    "length = 10 \n",
    "duration = timedelta(days=length)\n",
    "dt = 90 #toggle between - or + to pick backwards or forwards\n",
    "N = len(clat) # number of deploying locations\n",
    "n = 1 # 1000   # number of particles per location\n",
    "dmin = list(np.zeros(len(clat))) #minimum depth\n",
    "dd = 5 #max depth difference from dmin\n",
    "x_offset, y_offset, zvals = p_deploy(N,n,dmin,dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c87107ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parcels import Variable\n",
    "\n",
    "class MPParticle(JITParticle):        \n",
    "    ro = Variable('ro', initial = 1025)           \n",
    "    diameter = Variable('diameter', initial = 1.6e-5)\n",
    "    length = Variable('length', initial = 61e-5)\n",
    "    sediment = Variable('sediment', initial = 0)\n",
    "    beached = Variable('beached', initial = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ceb066c-22eb-4ef5-abe1-dc051ad4cc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = np.zeros([N,n])\n",
    "lat = np.zeros([N,n])\n",
    "for i in range(N):\n",
    "    lon[i,:]=(clon[i] + x_offset[i,:])\n",
    "    lat[i,:]=(clat[i] + y_offset[i,:])\n",
    "z = zvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92d6511f-3d0c-4a98-ad32-0d4cb970a2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jvalenti/MOAD/results/beachingl20181001_1n_20181011_1n.nc\n"
     ]
    }
   ],
   "source": [
    "#Set start date time and the name of the output file\n",
    "name = 'beachingl' #name output file\n",
    "daterange = [start+timedelta(days=i) for i in range(length)]\n",
    "fn =  name + '_'.join(d.strftime('%Y%m%d')+'_1n' for d in [start, start+duration]) + '.nc'\n",
    "outfile = os.path.join(paths['out'], fn)\n",
    "print(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e63f2-3fb8-4526-b45a-ce5644646287",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "922eb3dc-e34d-4102-b1d4-4df9de8b2f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in the list of variables that you want to use as fields\n",
    "varlist=['U','V','W','R']\n",
    "filenames,variables,dimensions=filename_set(start,length,varlist,local)\n",
    "field_set=FieldSet.from_nemo(filenames, variables, dimensions, allow_time_extrapolation=True)\n",
    "\n",
    "varlist=['US','VS','WL']\n",
    "filenames,variables,dimensions=filename_set(start,length,varlist,local)\n",
    "\n",
    "us = Field.from_netcdf(filenames['US'], variables['US'], dimensions,allow_time_extrapolation=True)\n",
    "vs = Field.from_netcdf(filenames['VS'], variables['VS'], dimensions,allow_time_extrapolation=True)\n",
    "wl = Field.from_netcdf(filenames['WL'], variables['WL'], dimensions,allow_time_extrapolation=True)\n",
    "field_set.add_field(us)\n",
    "field_set.add_field(vs)\n",
    "field_set.add_field(wl)\n",
    "field_set.add_vector_field(VectorField(\"stokes\", us, vs, wl))\n",
    "\n",
    "filenames,variables,dimensions=filename_set(start,length,['Bathy'],local)\n",
    "Bth = Field.from_netcdf(filenames['Bathy'], variables['Bathy'], dimensions,allow_time_extrapolation=True)\n",
    "field_set.add_field(Bth)\n",
    "\n",
    "filenames,variables,dimensions=filename_set(start,length,['D'],local)\n",
    "Distc = Field.from_netcdf(filenames['D'], variables['D'], dimensions,allow_time_extrapolation=True)\n",
    "field_set.add_field(Distc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53f87621-a497-4575-85ba-18ec93118e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Compiled ArrayMPParticleAdvectionRK4_3DBuoyancyStokes_driftBeaching ==> /tmp/parcels-2894/libbfdd93cb27bc070ff3b5e1f0bbfd37d7_0.so\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particle 1670 lost !! [5400.0, 2.9807588619550494, 50.44184197281319, -126.01293494749355]\n",
      "Particle 1678 lost !! [5400.0, 0.5632560664740993, 50.46176548261293, -126.09936757039716]\n",
      "Particle 1671 lost !! [17550.0, 0.2817091610034112, 50.464542307800606, -125.99991514343073]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Temporary output files are stored in /home/jvalenti/MOAD/results/out-HNQIAJPS.\n",
      "INFO: You can use \"parcels_convert_npydir_to_netcdf /home/jvalenti/MOAD/results/out-HNQIAJPS\" to convert these to a NetCDF file during the run.\n",
      "  2% (23400.0 of 864000.0) |             | Elapsed Time: 0:00:07 ETA:   0:08:57"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particle 1662 lost !! [28800.0, 16.406950875601506, 50.42776844285434, -125.99921960603133]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47% (410400.0 of 864000.0) |#####       | Elapsed Time: 0:04:51 ETA:   0:04:44"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct cell not found for (-124.779693, 48.498847) after 1000000 iterations\n",
      "Debug info: old particle indices: (yi, xi) 415 0\n",
      "            new particle indices: (yi, xi) 415 42\n",
      "            Mesh 2d shape:  898 398\n",
      "            Relative particle position:  (xsi, eta) -4.3019858001223106e+01 3.7147873757504585e-01\n",
      "Particle 1135 lost !! [416970.0, 0.7531745293111922, 48.49878284694112, -124.77953485658662]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (864000.0 of 864000.0) |############| Elapsed Time: 0:10:12 Time:  0:10:12\n",
      "/home/jvalenti/conda_envs/parcels/lib/python3.9/site-packages/numpy/lib/arraysetops.py:270: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ar = np.asanyarray(ar)\n"
     ]
    }
   ],
   "source": [
    "# #Load Salish output as fields\n",
    "#field_set = FieldSet.from_nemo(filenames, variables, dimensions, allow_time_extrapolation=True)\n",
    "pset = ParticleSet.from_list(field_set, MPParticle, lon=lon, lat=lat, depth=z, time=start+timedelta(hours=2))\n",
    "\n",
    "k_sink = pset.Kernel(Buoyancy)\n",
    "k_waves = pset.Kernel(Stokes_drift)\n",
    "k_beach = pset.Kernel(Beaching)\n",
    "\n",
    "pset.execute(AdvectionRK4_3D + k_sink + k_waves + k_beach,\n",
    "             runtime=duration, \n",
    "             dt=dt,\n",
    "             output_file=pset.ParticleFile(name=outfile, outputdt=timedelta(hours=1)),\n",
    "             recovery={ErrorCode.ErrorOutOfBounds: DeleteParticle})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
