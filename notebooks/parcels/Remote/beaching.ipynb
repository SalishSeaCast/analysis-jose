{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3249b069-318c-46cf-a0ab-422a39d81733",
   "metadata": {},
   "source": [
    "# **Template OP on salish**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b3cacf0-e987-4dcc-85ad-fa33f293ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "from parcels import FieldSet, Field, VectorField, ParticleSet, JITParticle, ErrorCode, ParcelsRandom\n",
    "\n",
    "sys.path.append('/home/jvalenti/MOAD/analysis-jose/notebooks/parcels')\n",
    "from Kernels_beaching import DeleteParticle, Buoyancy, AdvectionRK4_3D, Stokes_drift, Beaching\n",
    "from OP_functions_beaching import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10e0ace",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "941b8dd3-eebb-4149-af84-781e66652a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "local = 0 #Set to 0 when working on server\n",
    "paths = path(local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "206d74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dat=xr.open_dataset(get_WW3_path(datetime(2018, 12, 23)))\n",
    "path_NEMO = make_prefix(datetime(2018, 12, 23), paths['NEMO'])\n",
    "Dat0=xr.open_dataset(path_NEMO + '_grid_W.nc')\n",
    "Dat=xr.open_dataset(path_NEMO + '_grid_T.nc')\n",
    "coord=xr.open_dataset(paths['coords'],decode_times=False)\n",
    "WW3 = xr.open_dataset(get_WW3_path(datetime(2018, 12, 23)))\n",
    "batt=xr.open_dataset(paths['mask'],decode_times=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879cd801",
   "metadata": {},
   "source": [
    "## Define and save mask for distance to coast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "518b09b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def maskcoast(ilat,jlon):\n",
    "#     baty = batt.mbathy[0,:,:]\n",
    "#     maski = 0\n",
    "#     if baty[ilat,jlon]>1e-1:\n",
    "#         if baty[ilat+1,jlon] == 0 or baty[ilat+1,jlon+1] == 0 or baty[ilat+1,jlon-1] == 0:\n",
    "#             maski = 1\n",
    "#         elif baty[ilat,jlon] == 0 or baty[ilat,jlon+1] == 0 or baty[ilat,jlon-1] == 0:\n",
    "#             maski = 1\n",
    "#         elif baty[ilat-1,jlon] == 0 or baty[ilat-1,jlon+1] == 0 or baty[ilat-1,jlon-1] == 0:\n",
    "#             maski = 1\n",
    "#     return maski\n",
    "# maskd = np.zeros(batt.mbathy.shape)\n",
    "# baty = batt.mbathy[0,:,:]\n",
    "# for i in range(baty.shape[0]):\n",
    "#     for j in range(baty.shape[1]):\n",
    "#         maskd[0,i,j]=maskcoast(i,j)\n",
    "# batt=xr.open_dataset(paths['mask'],decode_times=False)\n",
    "# dist=xr.DataArray(attrs={'d':maskd})\n",
    "# batt['d']=(batt.mbathy.dims,maskd)\n",
    "# batt.to_netcdf(path='/ocean/jvalenti/MOAD/grid/mesh_maskd201702.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10b6fba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clat,clon = p_unidist(coord.gphif[0,:,:],coord.glamf[0,:,:],batt.mbathy[0,:,:],10,10)\n",
    "with open('clat.txt') as f:\n",
    "    clat = f.read()\n",
    "    clat= clat[1:-1]\n",
    "    clat0 = clat.split(\",\")\n",
    "    f.close()\n",
    "with open('clon.txt') as f:\n",
    "    clon = f.read()\n",
    "    clon=clon[1:-1]\n",
    "    clon0 = clon.split(\",\")\n",
    "    f.close()\n",
    "    \n",
    "clat,clon=[],[]\n",
    "for i in range(len(clat0)):\n",
    "    clat.append(float(clat0[i]))\n",
    "    clon.append(float(clon0[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c4bf2f-db05-4d5f-b4bb-bdaad6578599",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28a99025-a33d-4d66-9e39-aab453f279b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2018, 10, 1) #Start date\n",
    "# Set Time length [days] and timestep [seconds]\n",
    "length = 1 \n",
    "duration = timedelta(days=length)\n",
    "dt = 90 #toggle between - or + to pick backwards or forwards\n",
    "N = len(clat) # number of deploying locations\n",
    "n = 1 # 1000   # number of particles per location\n",
    "dmin = list(np.zeros(len(clat))) #minimum depth\n",
    "dd = 5 #max depth difference from dmin\n",
    "x_offset, y_offset, zvals = p_deploy(N,n,dmin,dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c87107ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parcels import Variable\n",
    "\n",
    "class MPParticle(JITParticle):        \n",
    "    ro = Variable('ro', initial = 1380)           \n",
    "    diameter = Variable('diameter', initial = 1.6e-5)\n",
    "    length = Variable('length', initial = 61e-5)\n",
    "    sediment = Variable('sediment', initial = 0)\n",
    "    beached = Variable('beached', initial = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ceb066c-22eb-4ef5-abe1-dc051ad4cc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = np.zeros([N,n])\n",
    "lat = np.zeros([N,n])\n",
    "for i in range(N):\n",
    "    lon[i,:]=(clon[i] + x_offset[i,:])\n",
    "    lat[i,:]=(clat[i] + y_offset[i,:])\n",
    "z = zvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92d6511f-3d0c-4a98-ad32-0d4cb970a2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jvalenti/MOAD/results/beaching20181001_1n_20181002_1n.nc\n"
     ]
    }
   ],
   "source": [
    "#Set start date time and the name of the output file\n",
    "name = 'beaching' #name output file\n",
    "daterange = [start+timedelta(days=i) for i in range(length)]\n",
    "fn =  name + '_'.join(d.strftime('%Y%m%d')+'_1n' for d in [start, start+duration]) + '.nc'\n",
    "outfile = os.path.join(paths['out'], fn)\n",
    "print(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e63f2-3fb8-4526-b45a-ce5644646287",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "922eb3dc-e34d-4102-b1d4-4df9de8b2f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: File /ocean/jvalenti/MOAD/grid/coordinates_seagrid_SalishSea201702.nc could not be decoded properly by xarray (version 0.19.0).\n",
      "         It will be opened with no decoding. Filling values might be wrongly parsed.\n"
     ]
    }
   ],
   "source": [
    "#Fill in the list of variables that you want to use as fields\n",
    "varlist=['U','V','W','R']\n",
    "filenames,variables,dimensions=filename_set(start,length,varlist,local)\n",
    "field_set=FieldSet.from_nemo(filenames, variables, dimensions, allow_time_extrapolation=True)\n",
    "\n",
    "varlist=['US','VS','WL']\n",
    "filenames,variables,dimensions=filename_set(start,length,varlist,local)\n",
    "\n",
    "us = Field.from_netcdf(filenames['US'], variables['US'], dimensions,allow_time_extrapolation=True)\n",
    "vs = Field.from_netcdf(filenames['VS'], variables['VS'], dimensions,allow_time_extrapolation=True)\n",
    "wl = Field.from_netcdf(filenames['WL'], variables['WL'], dimensions,allow_time_extrapolation=True)\n",
    "field_set.add_field(us)\n",
    "field_set.add_field(vs)\n",
    "field_set.add_field(wl)\n",
    "field_set.add_vector_field(VectorField(\"stokes\", us, vs, wl))\n",
    "\n",
    "filenames,variables,dimensions=filename_set(start,length,['Bathy'],local)\n",
    "Bth = Field.from_netcdf(filenames['Bathy'], variables['Bathy'], dimensions,allow_time_extrapolation=True)\n",
    "field_set.add_field(Bth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53f87621-a497-4575-85ba-18ec93118e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Compiled ArrayMPParticleAdvectionRK4_3DBuoyancyStokes_drift ==> /tmp/parcels-2894/lib443b8b580526f1070bfe75b43091bd6f_0.so\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particle 3324 lost !! [5400.0, 3.1665896505419564, 50.445370529070736, -126.01713916776767]\n",
      "Particle 3338 lost !! [5400.0, 4.77081063736257, 50.4473312523828, -126.06284156751235]\n",
      "Particle 3339 lost !! [5400.0, 2.3008386812720545, 50.45873102462346, -126.0254409348264]\n",
      "Particle 3340 lost !! [5400.0, 3.7368314604624295, 50.46575668473586, -126.00059523752915]\n",
      "Particle 3347 lost !! [5400.0, 0.6124347532022645, 50.459751532340206, -126.09993151903237]\n",
      "Particle 3348 lost !! [5400.0, 0.1483663196828655, 50.465996407585266, -126.07564544452435]\n",
      "Particle 3355 lost !! [5400.0, 4.807910152410411, 50.47519751980796, -126.13810495752902]\n",
      "Particle 3356 lost !! [5400.0, 2.4004030096966256, 50.47846953342501, -126.11379622760758]\n",
      "Particle 3325 lost !! [14760.0, 5.01663133380272, 50.44140428849729, -125.99974468398645]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Temporary output files are stored in /home/jvalenti/MOAD/results/out-NGIJWTNF.\n",
      "INFO: You can use \"parcels_convert_npydir_to_netcdf /home/jvalenti/MOAD/results/out-NGIJWTNF\" to convert these to a NetCDF file during the run.\n",
      " 18% (16200.0 of 86400.0) |##            | Elapsed Time: 0:00:02 ETA:   0:01:24"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particle 3313 lost !! [23220.0, 62.16715870877235, 50.43645320179828, -125.99939286108611]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% (18000.0 of 86400.0) |##            | Elapsed Time: 0:00:03 ETA:   0:00:56"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particle 3305 lost !! [25020.0, 11.13349311446886, 50.4349049190359, -125.99890531219944]\n",
      "Particle 3307 lost !! [25020.0, 4.4982726894495535, 50.4443472153475, -125.99981465059535]\n",
      "Particle 3314 lost !! [23850.0, 37.894860544712536, 50.43853520778735, -125.99962874595812]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25% (21600.0 of 86400.0) |###           | Elapsed Time: 0:00:06 ETA:   0:00:54"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particle 3298 lost !! [27000.0, 6.36851431379382, 50.41932378635946, -125.99979217629857]\n",
      "Particle 3306 lost !! [27360.0, 32.45902927564918, 50.43272815335016, -125.99953001311862]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27% (23400.0 of 86400.0) |###           | Elapsed Time: 0:00:09 ETA:   0:01:34"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particle 3319 lost !! [29520.0, 50.600340648840934, 50.452253713365025, -125.99991414769156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29% (25200.0 of 86400.0) |####          | Elapsed Time: 0:00:10 ETA:   0:00:59"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particle 3283 lost !! [31680.0, 47.465033765495704, 50.42648814186377, -125.99910566924336]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35% (30600.0 of 86400.0) |####          | Elapsed Time: 0:00:15 ETA:   0:01:20"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particle 3276 lost !! [36360.0, 9.5460723368446, 50.434240948643684, -125.99969216784476]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95% (82800.0 of 86400.0) |############# | Elapsed Time: 0:00:49 ETA:   0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particle 3327 lost !! [87480.0, 11.952174989132324, 50.430866054588606, -125.99988135213009]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (86400.0 of 86400.0) |##############| Elapsed Time: 0:00:50 Time:  0:00:50\n",
      "/home/jvalenti/conda_envs/parcels/lib/python3.9/site-packages/numpy/lib/arraysetops.py:270: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ar = np.asanyarray(ar)\n"
     ]
    }
   ],
   "source": [
    "# #Load Salish output as fields\n",
    "#field_set = FieldSet.from_nemo(filenames, variables, dimensions, allow_time_extrapolation=True)\n",
    "pset = ParticleSet.from_list(field_set, MPParticle, lon=lon, lat=lat, depth=z, time=start+timedelta(hours=2))\n",
    "\n",
    "k_sink = pset.Kernel(Buoyancy)\n",
    "k_waves = pset.Kernel(Stokes_drift)\n",
    "\n",
    "pset.execute(AdvectionRK4_3D + k_sink + k_waves,\n",
    "             runtime=duration, \n",
    "             dt=dt,\n",
    "             output_file=pset.ParticleFile(name=outfile, outputdt=timedelta(hours=1)),\n",
    "             recovery={ErrorCode.ErrorOutOfBounds: DeleteParticle})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
