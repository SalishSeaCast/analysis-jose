{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3249b069-318c-46cf-a0ab-422a39d81733",
   "metadata": {},
   "source": [
    "# **Template OP on salish**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b3cacf0-e987-4dcc-85ad-fa33f293ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "from parcels import FieldSet, Field, VectorField, ParticleSet, JITParticle, ErrorCode, AdvectionRK4, AdvectionRK4_3D\n",
    "\n",
    "sys.path.append('/home/jvalenti/MOAD/analysis-jose/notebooks/parcels')\n",
    "from Kernels import DeleteParticle, Buoyancy\n",
    "from OP_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "941b8dd3-eebb-4149-af84-781e66652a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "local = 0 #Set to 0 when working on server\n",
    "paths = path(local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "206d74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dat=xr.open_dataset(get_WW3_path(datetime(2018, 12, 23)))\n",
    "path_NEMO = make_prefix(datetime(2018, 12, 23), paths['NEMO'])\n",
    "Dat0=xr.open_dataset(path_NEMO + '_grid_W.nc')\n",
    "Dat=xr.open_dataset(path_NEMO + '_grid_T.nc')\n",
    "coord=xr.open_dataset(paths['coordsWW3'],decode_times=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c4bf2f-db05-4d5f-b4bb-bdaad6578599",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28a99025-a33d-4d66-9e39-aab453f279b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2018, 12, 23) #Start date\n",
    "# Set Time length [days] and timestep [seconds]\n",
    "length = 5\n",
    "duration = timedelta(days=length)\n",
    "dt = 90 #toggle between - or + to pick backwards or forwards\n",
    "N = 6 # number of deploying locations\n",
    "n = 100 # 1000   # number of particles per location\n",
    "dmin = [0,0,0,0,0,70] #minimum depth\n",
    "dd = 20 #max depth difference from dmin\n",
    "x_offset, y_offset, zvals = p_deploy(N,n,dmin,dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c87107ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parcels import Variable\n",
    "\n",
    "class PEParticle(JITParticle):         # Define a new particle class\n",
    "    ro = Variable('ro', initial = 960)             # desnsity PE\n",
    "    size = Variable('size', initial = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0a3c7aa-7f4e-42a1-a091-8cac7c2dd102",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dat=xr.open_dataset(paths['coords'],decode_times=False)\n",
    "outf_lat=Dat['nav_lat'][445,304]\n",
    "outf_lon=Dat['nav_lon'][445,304]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ceb066c-22eb-4ef5-abe1-dc051ad4cc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = np.zeros([N,n])\n",
    "lat = np.zeros([N,n])\n",
    "# Execute run\n",
    "clon, clat = [-123.901172,-125.155849,-123.207648,-122.427508,-123.399769,float(outf_lon)], [49.186308,49.975326,49.305448,47.622403,48.399420,float(outf_lat)]  # choose horizontal centre of the particle cloud\n",
    "for i in range(N):\n",
    "    lon[i,:]=(clon[i] + x_offset[i,:])\n",
    "    lat[i,:]=(clat[i] + y_offset[i,:])\n",
    "z = zvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92d6511f-3d0c-4a98-ad32-0d4cb970a2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jvalenti/MOAD/analysis-jose/notebooks/results/Waves120181223_1n_20181228_1n.nc\n"
     ]
    }
   ],
   "source": [
    "#Set start date time and the name of the output file\n",
    "name = 'Waves1' #name output file\n",
    "daterange = [start+timedelta(days=i) for i in range(length)]\n",
    "fn =  name + '_'.join(d.strftime('%Y%m%d')+'_1n' for d in [start, start+duration]) + '.nc'\n",
    "outfile = os.path.join(paths['out'], fn)\n",
    "print(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e63f2-3fb8-4526-b45a-ce5644646287",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "922eb3dc-e34d-4102-b1d4-4df9de8b2f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in the list of variables that you want to use as fields\n",
    "varlist=['U','V','W','R']\n",
    "filenames,variables,dimensions=filename_set(start,length,varlist,local)\n",
    "field_set=FieldSet.from_nemo(filenames, variables, dimensions, allow_time_extrapolation=True)\n",
    "\n",
    "varlist=['US','VS','WL']\n",
    "filenames,variables,dimensions=filename_set(start,length,varlist,local)\n",
    "\n",
    "us = Field.from_netcdf(filenames['US'], variables['US'], dimensions,fieldtype='U')\n",
    "vs = Field.from_netcdf(filenames['VS'], variables['VS'], dimensions,fieldtype='V')\n",
    "wl = Field.from_netcdf(filenames['WL'], variables['WL'], dimensions)\n",
    "field_set.add_field(us)\n",
    "field_set.add_field(vs)\n",
    "field_set.add_field(wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f0542f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Waves(particle, fieldset, time):\n",
    "    '''Stokes drift'''\n",
    " \n",
    "    #z = particle.depth\n",
    "    us0 = fieldset.uuss[time, particle.depth, particle.lat, particle.lon]\n",
    "    print(us0)\n",
    "    #vs0 = fieldset.vuss[time, particle.depth, particle.lat, particle.lon]\n",
    "    #wl = fieldset.lm[time, particle.depth, particle.lat, particle.lon]\n",
    "    #k = (2*math.pi)/wl\n",
    "    #us = us0*math.exp(-2*k*z)\n",
    "    #vs = vs0*math.exp(-2*k*z)\n",
    "    #print(z)\n",
    "    #particle.lon += 0 * particle.dt\n",
    "    #particle.lat += 0 * particle.dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53f87621-a497-4575-85ba-18ec93118e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Compiled ArrayJITParticleAdvectionRK4_3D ==> /tmp/parcels-2894/libd74567918fe3b69ee97d5cd45170a0c8_0.so\n",
      "INFO: Temporary output files are stored in /home/jvalenti/MOAD/analysis-jose/notebooks/results/out-UYTALWBD.\n",
      "INFO: You can use \"parcels_convert_npydir_to_netcdf /home/jvalenti/MOAD/analysis-jose/notebooks/results/out-UYTALWBD\" to convert these to a NetCDF file during the run.\n",
      "  7% (30600.0 of 432000.0) |             | Elapsed Time: 0:00:13 ETA:   0:08:21"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5297/1807522290.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#p_flt = pset.Kernel(Waves) #uncomment if you want to use additional kernels, also change the value of pset.Kernel to \"AdvectionRK4_3D + p_flt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m##pset.computeTimeChunk(allow_time_extrapolation=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m pset.execute(AdvectionRK4_3D, #+ p_flt, \n\u001b[0m\u001b[1;32m      8\u001b[0m              \u001b[0mruntime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m              \u001b[0mdt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda_envs/parcels/lib/python3.9/site-packages/parcels/particleset/baseparticleset.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, pyfunc, pyfunc_inter, endtime, runtime, dt, moviedt, recovery, output_file, movie_background_field, verbose_progress, postIterationCallbacks, callbackdt)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# If we don't perform interaction, only execute the normal kernel efficiently.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteraction_kernel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m                 self.kernel.execute(self, endtime=next_time, dt=dt, recovery=recovery, output_file=output_file,\n\u001b[0m\u001b[1;32m    459\u001b[0m                                     execute_once=execute_once)\n\u001b[1;32m    460\u001b[0m             \u001b[0;31m# Interaction: interleave the interaction and non-interaction kernel for each time step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda_envs/parcels/lib/python3.9/site-packages/parcels/kernel/kernelsoa.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, pset, endtime, dt, recovery, output_file, execute_once)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# Execute the kernel over the particle set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_jit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda_envs/parcels/lib/python3.9/site-packages/parcels/kernel/kernelsoa.py\u001b[0m in \u001b[0;36mexecute_jit\u001b[0;34m(self, pset, endtime, dt)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mfargs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc_double\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconst_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mparticle_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         return self._function(c_int(len(pset)), particle_data,\n\u001b[0m\u001b[1;32m    130\u001b[0m                               c_double(endtime), c_double(dt), *fargs)\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# #Load Salish output as fields\n",
    "#field_set = FieldSet.from_nemo(filenames, variables, dimensions, allow_time_extrapolation=True)\n",
    "pset = ParticleSet.from_list(field_set, JITParticle, lon=lon, lat=lat, depth=z, time=start+timedelta(hours=2))\n",
    "\n",
    "#p_flt = pset.Kernel(Waves) #uncomment if you want to use additional kernels, also change the value of pset.Kernel to \"AdvectionRK4_3D + p_flt\"\n",
    "##pset.computeTimeChunk(allow_time_extrapolation=1)\n",
    "pset.execute(AdvectionRK4_3D, #+ p_flt, \n",
    "             runtime=duration, \n",
    "             dt=dt,\n",
    "             output_file=pset.ParticleFile(name=outfile, outputdt=timedelta(hours=1)),\n",
    "             recovery={ErrorCode.ErrorOutOfBounds: DeleteParticle})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d091292",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
